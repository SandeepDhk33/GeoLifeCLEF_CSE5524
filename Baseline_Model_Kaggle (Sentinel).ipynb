{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06a5e89",
   "metadata": {},
   "source": [
    "# Baseline Model using Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f09ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7cb55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_patch_path(data_path, survey_id):\n",
    "    \"\"\"Construct the patch file path based on plot_id as './CD/AB/XXXXABCD.tiff'\"\"\"\n",
    "    path = data_path\n",
    "    for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "        path = os.path.join(path, d)\n",
    "\n",
    "    path = os.path.join(path, f\"{survey_id}.tiff\")\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize(band, low=2, high=98):\n",
    "    sorted_band = np.sort(band.flatten())\n",
    "    quantiles = np.percentile(sorted_band, np.linspace(low, high, len(sorted_band)))\n",
    "    normalized_band = np.interp(band.flatten(), sorted_band, quantiles).reshape(band.shape)\n",
    "    \n",
    "    min_val, max_val = np.min(normalized_band), np.max(normalized_band)\n",
    "    \n",
    "    # Prevent division by zero if min_val == max_val\n",
    "    if max_val == min_val:\n",
    "        return np.zeros_like(normalized_band, dtype=np.float32)  # Return an array of zeros\n",
    "\n",
    "    # Perform normalization (min-max scaling)\n",
    "    return ((normalized_band - min_val) / (max_val - min_val)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_dir, metadata, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.metadata = metadata\n",
    "        self.metadata = self.metadata.dropna(subset=\"speciesId\").reset_index(drop=True)\n",
    "        self.metadata['speciesId'] = self.metadata['speciesId'].astype(int)\n",
    "        self.label_dict = self.metadata.groupby('surveyId')['speciesId'].apply(list).to_dict()\n",
    "        \n",
    "        self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "        species_ids = self.label_dict.get(survey_id, [])  # Get list of species IDs for the survey ID\n",
    "        label = torch.zeros(num_classes)  # Initialize label tensor\n",
    "        for species_id in species_ids:\n",
    "            label_id = species_id\n",
    "            label[label_id] = 1  # Set the corresponding class index to 1 for each species\n",
    "        \n",
    "        # Read TIFF files (multispectral bands)\n",
    "        tiff_path = construct_patch_path(self.data_dir, survey_id)\n",
    "        with rasterio.open(tiff_path) as dataset:\n",
    "            image = dataset.read(out_dtype=np.float32)  # Read all bands\n",
    "            image = np.array([quantile_normalize(band) for band in image])  # Apply quantile normalization\n",
    "\n",
    "        image = np.transpose(image, (1, 2, 0))  # Convert to HWC format\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label, survey_id\n",
    "    \n",
    "class TestDataset(TrainDataset):\n",
    "    def __init__(self, data_dir, metadata, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.metadata = metadata\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "        \n",
    "        # Read TIFF files (multispectral bands)\n",
    "        tiff_path = construct_patch_path(self.data_dir, survey_id)\n",
    "        with rasterio.open(tiff_path) as dataset:\n",
    "            image = dataset.read(out_dtype=np.float32)  # Read all bands\n",
    "            image = np.array([quantile_normalize(band) for band in image])  # Apply quantile normalization\n",
    "\n",
    "        image = np.transpose(image, (1, 2, 0))  # Convert to HWC format\n",
    "        \n",
    "        image = self.transform(image)\n",
    "        return image, survey_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea93d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load Training metadata\n",
    "train_data_path = \"/fs/scratch/PAS2985/group_23/SatelitePatches/PA-train\"\n",
    "train_metadata_path = \"/fs/scratch/PAS2985/group_23/training_data.csv\"\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "train_dataset = TrainDataset(train_data_path, train_metadata, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Load Test metadata\n",
    "test_data_path = \"/fs/scratch/PAS2985/group_23/SatelitePatches/PA-train\"\n",
    "test_metadata_path = \"/fs/scratch/PAS2985/group_23/test_data.csv\"\n",
    "test_metadata = pd.read_csv(test_metadata_path)\n",
    "test_dataset = TestDataset(test_data_path, test_metadata, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346945f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cuda is available\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"DEVICE = CUDA\")\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 25\n",
    "positive_weigh_factor = 1.0\n",
    "num_classes = 11255 # Number of all unique classes within the PO and PA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2))\n",
    "model.fc = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set seed for Python's built-in random number generator\n",
    "    torch.manual_seed(seed)\n",
    "    # Set seed for numpy\n",
    "    np.random.seed(seed)\n",
    "    # Set seed for CUDA if available\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # Set cuDNN's random number generator seed for deterministic behavior\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(77)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2d326",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fcf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training for {num_epochs} epochs started.\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, targets, _) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "\n",
    "        pos_weight = targets*positive_weigh_factor  # All positive weights are equal to 10\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 348 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\"Scheduler:\",scheduler.state_dict())\n",
    "\n",
    "# Save the trained model\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"resnet_baseline.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e9a71",
   "metadata": {},
   "source": [
    "# Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3bb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    surveys = []\n",
    "    top_k_indices = None\n",
    "    for data, surveyID in tqdm.tqdm(test_loader, total=len(test_loader)):\n",
    "\n",
    "        data = data.to(device)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "        # Sellect top-25 values as predictions\n",
    "        top_25 = np.argsort(-predictions, axis=1)[:, :25] \n",
    "        if top_k_indices is None:\n",
    "            top_k_indices = top_25\n",
    "        else:\n",
    "            top_k_indices = np.concatenate((top_k_indices, top_25), axis=0)\n",
    "\n",
    "        surveys.extend(surveyID.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concatenated = [' '.join(map(str, row)) for row in top_k_indices]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {'surveyId': surveys,\n",
    "     'predictions': data_concatenated,\n",
    "    }).to_csv(\"baseline_submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
